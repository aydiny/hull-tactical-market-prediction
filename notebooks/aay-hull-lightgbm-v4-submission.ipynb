{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31fd6844",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:00.515479Z",
     "iopub.status.busy": "2025-12-12T13:26:00.515217Z",
     "iopub.status.idle": "2025-12-12T13:26:02.346665Z",
     "shell.execute_reply": "2025-12-12T13:26:02.345302Z"
    },
    "papermill": {
     "duration": 1.840817,
     "end_time": "2025-12-12T13:26:02.348310",
     "exception": false,
     "start_time": "2025-12-12T13:26:00.507493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/hull-tactical-market-prediction/train.csv\n",
      "/kaggle/input/hull-tactical-market-prediction/test.csv\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_inference_server.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_gateway.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__init__.py\n",
      "/kaggle/input/pandas-ta-man/pandas_ta-0.3.14b.tar.gz.tar\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd5044",
   "metadata": {
    "papermill": {
     "duration": 0.005589,
     "end_time": "2025-12-12T13:26:02.360020",
     "exception": false,
     "start_time": "2025-12-12T13:26:02.354431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b179279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:02.372914Z",
     "iopub.status.busy": "2025-12-12T13:26:02.372509Z",
     "iopub.status.idle": "2025-12-12T13:26:12.683040Z",
     "shell.execute_reply": "2025-12-12T13:26:12.681893Z"
    },
    "papermill": {
     "duration": 10.319371,
     "end_time": "2025-12-12T13:26:12.685085",
     "exception": false,
     "start_time": "2025-12-12T13:26:02.365714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pandas-ta-man/pandas_ta-0.3.14b.tar.gz.tar\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pandas_ta==0.3.14b0) (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta==0.3.14b0) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta==0.3.14b0) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta==0.3.14b0) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta==0.3.14b0) (2025.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (2.4.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta==0.3.14b0) (1.17.0)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas->pandas_ta==0.3.14b0) (2024.2.0)\r\n",
      "Building wheels for collected packages: pandas_ta\r\n",
      "  Building wheel for pandas_ta (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218910 sha256=410cd2a0b11da87486431c7a2841640fe0b9b23367945f9e5dd71a27306008c1\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/cf/67/d5/b79954a9750c845c41651cab5827d7b0ed96d7253de184984b\r\n",
      "Successfully built pandas_ta\r\n",
      "Installing collected packages: pandas_ta\r\n",
      "Successfully installed pandas_ta-0.3.14b0\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from dataclasses import dataclass, asdict\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import kaggle_evaluation.default_inference_server\n",
    "\n",
    "!pip install /kaggle/input/pandas-ta-man/pandas_ta-0.3.14b.tar.gz.tar\n",
    "import pandas_ta as ta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6f94f",
   "metadata": {
    "papermill": {
     "duration": 0.006091,
     "end_time": "2025-12-12T13:26:12.697941",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.691850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Project Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab41b26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:12.712051Z",
     "iopub.status.busy": "2025-12-12T13:26:12.711260Z",
     "iopub.status.idle": "2025-12-12T13:26:12.724383Z",
     "shell.execute_reply": "2025-12-12T13:26:12.723056Z"
    },
    "papermill": {
     "duration": 0.022198,
     "end_time": "2025-12-12T13:26:12.726022",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.703824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/hull-tactical-market-prediction/train.csv\n",
      "/kaggle/input/hull-tactical-market-prediction/test.csv\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_inference_server.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_gateway.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__init__.py\n",
      "/kaggle/input/pandas-ta-man/pandas_ta-0.3.14b.tar.gz.tar\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1a9ea",
   "metadata": {
    "papermill": {
     "duration": 0.005863,
     "end_time": "2025-12-12T13:26:12.738383",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.732520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5624ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:12.751538Z",
     "iopub.status.busy": "2025-12-12T13:26:12.751219Z",
     "iopub.status.idle": "2025-12-12T13:26:12.756128Z",
     "shell.execute_reply": "2025-12-12T13:26:12.755332Z"
    },
    "papermill": {
     "duration": 0.013708,
     "end_time": "2025-12-12T13:26:12.757977",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.744269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ============ PATHS ============\n",
    "DATA_PATH: Path = Path('/kaggle/input/hull-tactical-market-prediction/')\n",
    "#DATA_PATH: Path = hull_tactical_market_prediction_path\n",
    "\n",
    "# ============ MODEL CONFIGS ============\n",
    "#CV: int = 10                                    # Number of cross validation folds in the model fitting\n",
    "#L1_RATIO: float = 0.5                           # ElasticNet mixing parameter\n",
    "ALPHAS: np.ndarray = np.logspace(-4, 2, 100)    # Constant that multiplies the penalty terms\n",
    "MAX_ITER: int = 1000000                         # The maximum number of iterations\n",
    "N_FUTURE=1                                      # Number of days into future to predict stock price\n",
    "TIME_STEPS = 5                                  # Look-back period for LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c17e4b",
   "metadata": {
    "papermill": {
     "duration": 0.005957,
     "end_time": "2025-12-12T13:26:12.770056",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.764099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Seed Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593c534d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:12.783798Z",
     "iopub.status.busy": "2025-12-12T13:26:12.783370Z",
     "iopub.status.idle": "2025-12-12T13:26:12.788463Z",
     "shell.execute_reply": "2025-12-12T13:26:12.787653Z"
    },
    "papermill": {
     "duration": 0.013621,
     "end_time": "2025-12-12T13:26:12.789953",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.776332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(237)\n",
    "seed=237"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7b55c",
   "metadata": {
    "papermill": {
     "duration": 0.005787,
     "end_time": "2025-12-12T13:26:12.801805",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.796018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad2bcb11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:12.815813Z",
     "iopub.status.busy": "2025-12-12T13:26:12.815384Z",
     "iopub.status.idle": "2025-12-12T13:26:12.822966Z",
     "shell.execute_reply": "2025-12-12T13:26:12.822117Z"
    },
    "papermill": {
     "duration": 0.016212,
     "end_time": "2025-12-12T13:26:12.824655",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.808443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_trainset() -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the training dataset.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The preprocessed training DataFrame.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(DATA_PATH, \"train.csv\")\n",
    "    return (\n",
    "        pl.read_csv(file_path)\n",
    "        .rename({'market_forward_excess_returns':'target'})\n",
    "        .with_columns(\n",
    "            pl.exclude('date_id').cast(pl.Float64, strict=False)\n",
    "        )\n",
    "        #.head(-10)\n",
    "    )\n",
    "\n",
    "def load_testset() -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads and preprocesses the testing dataset.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: The preprocessed testing DataFrame.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(DATA_PATH, \"test.csv\")\n",
    "    return (\n",
    "        pl.read_csv(file_path)\n",
    "        .rename({'lagged_forward_returns':'target'})\n",
    "        .with_columns(\n",
    "            pl.exclude('date_id').cast(pl.Float64, strict=False)\n",
    "        )\n",
    "    )\n",
    "\n",
    "def join_train_test_dataframes(train: pl.DataFrame, test: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Joins two dataframes by common columns and concatenates them vertically.\n",
    "\n",
    "    Args:\n",
    "        train (pl.DataFrame): The training DataFrame.\n",
    "        test (pl.DataFrame): The testing DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pl.DataFrame: A single DataFrame with vertically stacked data from common columns.\n",
    "    \"\"\"\n",
    "    common_columns: list[str] = [col for col in train.columns if col in test.columns]\n",
    "\n",
    "    return pl.concat([train.select(common_columns), test.select(common_columns)], how=\"vertical\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b0bafd",
   "metadata": {
    "papermill": {
     "duration": 0.006433,
     "end_time": "2025-12-12T13:26:12.837359",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.830926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Generate Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0efd1c91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:12.851711Z",
     "iopub.status.busy": "2025-12-12T13:26:12.851192Z",
     "iopub.status.idle": "2025-12-12T13:26:13.340925Z",
     "shell.execute_reply": "2025-12-12T13:26:13.339457Z"
    },
    "papermill": {
     "duration": 0.498308,
     "end_time": "2025-12-12T13:26:13.342502",
     "exception": false,
     "start_time": "2025-12-12T13:26:12.844194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 98)\n",
      "┌─────────┬─────┬─────┬─────┬───┬───────────┬─────────────────┬────────────────┬───────────┐\n",
      "│ date_id ┆ D1  ┆ D2  ┆ D3  ┆ … ┆ V9        ┆ forward_returns ┆ risk_free_rate ┆ target    │\n",
      "│ ---     ┆ --- ┆ --- ┆ --- ┆   ┆ ---       ┆ ---             ┆ ---            ┆ ---       │\n",
      "│ i64     ┆ f64 ┆ f64 ┆ f64 ┆   ┆ f64       ┆ f64             ┆ f64            ┆ f64       │\n",
      "╞═════════╪═════╪═════╪═════╪═══╪═══════════╪═════════════════╪════════════════╪═══════════╡\n",
      "│ 9045    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ -0.411743 ┆ 0.001852        ┆ 0.000147       ┆ 0.001395  │\n",
      "│ 9046    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ -0.468078 ┆ 0.003463        ┆ 0.000146       ┆ 0.003006  │\n",
      "│ 9047    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ -0.4878   ┆ 0.000117        ┆ 0.000144       ┆ -0.000339 │\n",
      "└─────────┴─────┴─────┴─────┴───┴───────────┴─────────────────┴────────────────┴───────────┘\n",
      "shape: (3, 99)\n",
      "┌─────────┬─────┬─────┬─────┬───┬───────────┬──────────┬─────────────────────┬─────────────────────┐\n",
      "│ date_id ┆ D1  ┆ D2  ┆ D3  ┆ … ┆ is_scored ┆ target   ┆ lagged_risk_free_ra ┆ lagged_market_forwa │\n",
      "│ ---     ┆ --- ┆ --- ┆ --- ┆   ┆ ---       ┆ ---      ┆ te                  ┆ rd_excess_r…        │\n",
      "│ i64     ┆ f64 ┆ f64 ┆ f64 ┆   ┆ f64       ┆ f64      ┆ ---                 ┆ ---                 │\n",
      "│         ┆     ┆     ┆     ┆   ┆           ┆          ┆ f64                 ┆ f64                 │\n",
      "╞═════════╪═════╪═════╪═════╪═══╪═══════════╪══════════╪═════════════════════╪═════════════════════╡\n",
      "│ 8987    ┆ 0.0 ┆ 0.0 ┆ 1.0 ┆ … ┆ 1.0       ┆ 0.002312 ┆ 0.000156            ┆ 0.001845            │\n",
      "│ 8988    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ 1.0       ┆ 0.002891 ┆ 0.000156            ┆ 0.002424            │\n",
      "│ 8989    ┆ 0.0 ┆ 0.0 ┆ 0.0 ┆ … ┆ 0.0       ┆ 0.00831  ┆ 0.000156            ┆ 0.007843            │\n",
      "└─────────┴─────┴─────┴─────┴───┴───────────┴──────────┴─────────────────────┴─────────────────────┘\n",
      "(9048, 98)\n"
     ]
    }
   ],
   "source": [
    "train: pl.DataFrame = load_trainset()\n",
    "test: pl.DataFrame = load_testset()\n",
    "print(train.tail(3))\n",
    "print(test.tail(3))\n",
    "\n",
    "df_train=train.to_pandas()\n",
    "print (df_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beacc00",
   "metadata": {
    "papermill": {
     "duration": 0.006164,
     "end_time": "2025-12-12T13:26:13.355198",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.349034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Target for LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fecf811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:13.369147Z",
     "iopub.status.busy": "2025-12-12T13:26:13.368871Z",
     "iopub.status.idle": "2025-12-12T13:26:13.376340Z",
     "shell.execute_reply": "2025-12-12T13:26:13.375371Z"
    },
    "papermill": {
     "duration": 0.016305,
     "end_time": "2025-12-12T13:26:13.377828",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.361523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_LightGBM_target(df):\n",
    "    \"\"\"\n",
    "    Creates a Sharpe-Optimized 'Oracle' target.\n",
    "    0 = Cash (Bearish)\n",
    "    1 = Market (Neutral / Low Conviction Bull)\n",
    "    2 = Leverage (High Conviction Bull)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1. Define Thresholds (The \"Buffer Zone\")\n",
    "    # ---------------------------------------------------------\n",
    "    # We calculate the daily volatility (standard deviation) to know what a \"big move\" is.\n",
    "    # A common rule of thumb:\n",
    "    # - If return > 0.5 * Daily_Vol -> Worth Leveraging (2)\n",
    "    # - If return < 0.0             -> Cash (0)\n",
    "    # - In between                  -> Just Hold (1)\n",
    "\n",
    "    # Calculate rolling volatility (backward looking, then shifted back to align with current row)\n",
    "    # We use a small window to adapt to current regimes\n",
    "    daily_vol = df['forward_returns'].rolling(window=20).std().bfill()\n",
    "\n",
    "    threshold = 0.5 * daily_vol  # You can tune this (e.g., 0.2 to 1.0)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. Assign Initial Targets\n",
    "    # ---------------------------------------------------------\n",
    "    # Default to 1 (Hold)\n",
    "    targets = pd.Series(1, index=df.index)\n",
    "\n",
    "    # Set 0 (Cash) if return is negative\n",
    "    targets[df['forward_returns'] < -threshold] = 0\n",
    "\n",
    "    # Set 2 (Lev) ONLY if return is significantly positive (beats the threshold)\n",
    "    targets[df['forward_returns'] > threshold] = 2\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. The \"Black Swan\" Dampener (Your logic, improved)\n",
    "    # ---------------------------------------------------------\n",
    "    # If volatility is extreme, we remove the option to use Leverage (2).\n",
    "    # We force it down to 1 (Hold) or even 0 (Cash) if you want to be defensive.\n",
    "\n",
    "    # Calculate Z-Score of Volatility\n",
    "    rolling_vol_20 = df['forward_returns'].rolling(window=20).std()\n",
    "    long_term_mean = rolling_vol_20.rolling(window=252).mean()\n",
    "    long_term_std = rolling_vol_20.rolling(window=252).std()\n",
    "\n",
    "    vol_z_score = (rolling_vol_20 - long_term_mean) / (long_term_std + 1e-6)\n",
    "\n",
    "    # Alignment: We are creating a TARGET (Oracle), so we are allowed to peek at the\n",
    "    # volatility of the *period we are predicting*.\n",
    "    # So we shift the z-score backwards to match the target date.\n",
    "    future_vol_z_score = vol_z_score.shift(-1).fillna(0)\n",
    "\n",
    "    # Rule: If future volatility is > 2 Sigma, forbid Leverage.\n",
    "    mask_extreme_vol = future_vol_z_score > 2.0\n",
    "\n",
    "    # If it was 2 and vol is crazy, downgrade to 1\n",
    "    targets = np.where((mask_extreme_vol) & (targets == 2), 1, targets)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. CRITICAL: Return Integers for Multiclass\n",
    "    # ---------------------------------------------------------\n",
    "    return targets.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "768d5302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:13.392112Z",
     "iopub.status.busy": "2025-12-12T13:26:13.391843Z",
     "iopub.status.idle": "2025-12-12T13:26:13.399238Z",
     "shell.execute_reply": "2025-12-12T13:26:13.398339Z"
    },
    "papermill": {
     "duration": 0.016086,
     "end_time": "2025-12-12T13:26:13.400595",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.384509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_LightGBM_target_inference(df): \n",
    "    \"\"\"\n",
    "    Inference version: Grades the PAST based on the CURRENT data.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. IDENTIFY THE TRUTH\n",
    "    # In inference, 'lagged_forward_returns' at Index T IS the \"Forward Return\" of Index T-1.\n",
    "    # We calculate metrics directly on this column.\n",
    "    series_to_grade = df['lagged_forward_returns']\n",
    "\n",
    "    # 2. DEFINE THRESHOLDS (Same logic as training)\n",
    "    # Calculate volatility of the returns that JUST happened.\n",
    "    daily_vol = series_to_grade.rolling(window=20).std().bfill()\n",
    "    threshold = 0.5 * daily_vol \n",
    "\n",
    "    # 3. ASSIGN \"RAW\" TARGETS\n",
    "    # Note: These targets sit at Index T, but they describe the ideal action for Index T-1.\n",
    "    raw_targets = pd.Series(1, index=df.index) # Default Hold\n",
    "    \n",
    "    # If Today's return was bad, Yesterday should have been Cash\n",
    "    raw_targets[series_to_grade < -threshold] = 0\n",
    "    \n",
    "    # If Today's return was great, Yesterday should have been Lev\n",
    "    raw_targets[series_to_grade > threshold] = 2\n",
    "\n",
    "    # 4. BLACK SWAN DAMPENER (Corrected for Inference)\n",
    "    # We don't need shift(-1) here because 'series_to_grade' IS already the future relative to T-1.\n",
    "    # We just check if the return that just occurred was wildly volatile relative to history.\n",
    "    \n",
    "    rolling_vol_20 = series_to_grade.rolling(window=20).std()\n",
    "    long_term_mean = rolling_vol_20.rolling(window=252).mean()\n",
    "    long_term_std = rolling_vol_20.rolling(window=252).std()\n",
    "    \n",
    "    # Z-Score of the volatility we just experienced\n",
    "    current_vol_z_score = (rolling_vol_20 - long_term_mean) / (long_term_std + 1e-6)\n",
    "    \n",
    "    # If the move we just saw was a >2 Sigma event, we say \"Yesterday shouldn't have leveraged\"\n",
    "    mask_extreme_vol = current_vol_z_score > 2.0\n",
    "    \n",
    "    raw_targets = np.where((mask_extreme_vol) & (raw_targets == 2), 1, raw_targets)\n",
    "\n",
    "    # 5. THE FINAL SHIFT (Crucial Step)\n",
    "    # We calculated the answer for T-1, but the answer is currently sitting in Row T.\n",
    "    # We shift UP (-1) to put the answer into the correct row.\n",
    "    \n",
    "    # Row T-1 now contains the target derived from Row T's return.\n",
    "    # astype('Int64') allows for NaN values, which is appropriate for the last row where the target is unknown\n",
    "    pos_target_series = pd.Series(raw_targets).shift(-1).astype('Int64')\n",
    "    \n",
    "    # Note: The very last row (Today) will be NaN because we don't know Tomorrow's return yet.\n",
    "    # This is correct. We only need pos_target for history.\n",
    "    \n",
    "    return pos_target_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af93eb3",
   "metadata": {
    "papermill": {
     "duration": 0.005935,
     "end_time": "2025-12-12T13:26:13.412824",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.406889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom eval function (Competition metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ce60ef1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:13.426974Z",
     "iopub.status.busy": "2025-12-12T13:26:13.426639Z",
     "iopub.status.idle": "2025-12-12T13:26:13.434745Z",
     "shell.execute_reply": "2025-12-12T13:26:13.433975Z"
    },
    "papermill": {
     "duration": 0.017537,
     "end_time": "2025-12-12T13:26:13.436271",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.418734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CompetitionMetric:\n",
    "    def __init__(self, validation_df):\n",
    "        # We store the raw returns and risk-free rate for the validation set\n",
    "        self.returns = validation_df['forward_returns'].values\n",
    "        self.risk_free = validation_df['risk_free_rate'].values\n",
    "        self.market_returns = validation_df['forward_returns'].values\n",
    "\n",
    "    def feval(self, preds, train_data):\n",
    "        \"\"\"\n",
    "        Full Competition Metric (Sharpe + Vol Penalty + Return Penalty)\n",
    "        \"\"\"\n",
    "\n",
    "        n_rows = len(self.returns)\n",
    "        num_class = 3  # Hardcoded based on LightGBM objective='multiclass' and num_class=3\n",
    "\n",
    "        # Reshape predictions to (n_rows, num_class) regardless of initial shape\n",
    "        # This handles both (n_rows * num_class,) and (n_rows, num_class) inputs\n",
    "        preds_prob = preds.reshape((n_rows, num_class))\n",
    "\n",
    "        # Convert Probabilities to Weighted Position\n",
    "        # 0*Prob(0) + 1*Prob(1) + 2*Prob(2)\n",
    "        # Assuming class 0 is 0x leverage, class 1 is 1x leverage, class 2 is 2x leverage\n",
    "        position = (preds_prob[:, 1] * 1.0) + (preds_prob[:, 2] * 2.0)\n",
    "\n",
    "        # 2. Calculate Strategy Returns (Daily)\n",
    "        # Formula: Risk_Free * (Uninvested Part) + Position * (Market Return)\n",
    "        strategy_rets = self.risk_free * (1 - position) + position * self.returns\n",
    "\n",
    "        # 3. Calculate Excess Returns\n",
    "        strat_excess = strategy_rets - self.risk_free\n",
    "        market_excess = self.market_returns - self.risk_free\n",
    "\n",
    "        # 4. Calculate Annualized Stats (Approximate geometric mean for speed)\n",
    "        # Note: In the official metric, they use geometric mean: (1+r).prod()**(1/N) - 1\n",
    "        # For monitoring, arithmetic mean is usually 'close enough', but here is the exact math:\n",
    "\n",
    "        strat_geom_mean = (1 + strat_excess).prod()**(1/len(strat_excess)) - 1\n",
    "        market_geom_mean = (1 + market_excess).prod()**(1/len(market_excess)) - 1\n",
    "\n",
    "        strat_std = np.std(strategy_rets) # Std deviation of raw returns usually\n",
    "        market_std = np.std(self.market_returns)\n",
    "\n",
    "        if strat_std == 0: strat_std = 1e-6\n",
    "        if market_std == 0: market_std = 1e-6\n",
    "\n",
    "        # Annualize\n",
    "        trading_days = 252\n",
    "        sharpe = (strat_geom_mean / strat_std) * np.sqrt(trading_days)\n",
    "\n",
    "        strat_vol_annual = strat_std * np.sqrt(trading_days) * 100\n",
    "        market_vol_annual = market_std * np.sqrt(trading_days) * 100\n",
    "\n",
    "        # -----------------------------------------------------------\n",
    "        # 5. The Penalties\n",
    "        # -----------------------------------------------------------\n",
    "\n",
    "        # A. Volatility Penalty\n",
    "        # Punishment if Strategy Vol > 1.2x Market Vol\n",
    "        vol_ratio = strat_vol_annual / market_vol_annual\n",
    "        excess_vol = max(0, vol_ratio - 1.2)\n",
    "        vol_penalty = 1 + excess_vol\n",
    "\n",
    "        # B. Return Penalty (The missing piece)\n",
    "        # Punishment if Strategy Return < Market Return\n",
    "        # We assume the gap is calculated based on annual percentage differences\n",
    "        return_gap = max(0, (market_geom_mean - strat_geom_mean) * 100 * trading_days)\n",
    "        return_penalty = 1 + (return_gap**2) / 100\n",
    "\n",
    "        # 6. Final Score\n",
    "        final_score = sharpe / (vol_penalty * return_penalty)\n",
    "\n",
    "        return 'comp_score', final_score, True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d417d30b",
   "metadata": {
    "papermill": {
     "duration": 0.005865,
     "end_time": "2025-12-12T13:26:13.448592",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.442727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b827c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:13.461780Z",
     "iopub.status.busy": "2025-12-12T13:26:13.461227Z",
     "iopub.status.idle": "2025-12-12T13:26:13.466662Z",
     "shell.execute_reply": "2025-12-12T13:26:13.465918Z"
    },
    "papermill": {
     "duration": 0.013505,
     "end_time": "2025-12-12T13:26:13.467977",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.454472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_return_target_lags(df, df_LightGBM_target):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 1. The Critical Lags (Target & Return)\n",
    "    # We lag the 'forward_returns' to create 'past_returns'\n",
    "    # Note: 'forward_returns' at T is the return for T+1.\n",
    "    # So shift(1) gives us the return at T (Today's close).\n",
    "    # shift(2) gives us T-1 (Yesterday).\n",
    "\n",
    "    # Return Lags\n",
    "    df['forward_returns_lagged_1'] = df['lagged_forward_returns'].shift(1) # Return realized today\n",
    "    df['forward_returns_lagged_2'] = df['lagged_forward_returns'].shift(2) # Return realized yesterday\n",
    "    df['forward_returns_lagged_3'] = df['lagged_forward_returns'].shift(3)\n",
    "    df['forward_returns_lagged_5'] = df['lagged_forward_returns'].shift(5) # Weekly trend\n",
    "\n",
    "    # Target Lags (What was the ideal position yesterday?)\n",
    "    # Assuming 'target' is aligned to T\n",
    "    df['pos_target_t-1'] = df_LightGBM_target.shift(1)\n",
    "    df['pos_target_t-2'] = df_LightGBM_target.shift(2)\n",
    "    df['pos_target_t-3'] = df_LightGBM_target.shift(3)\n",
    "\n",
    "    # 2. Volatility (Derived)\n",
    "    # 5-day rolling volatility of returns\n",
    "    df['rolling_vol_5'] = df['forward_returns_lagged_1'].rolling(5).std()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69308fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:13.481998Z",
     "iopub.status.busy": "2025-12-12T13:26:13.481199Z",
     "iopub.status.idle": "2025-12-12T13:26:13.488337Z",
     "shell.execute_reply": "2025-12-12T13:26:13.487536Z"
    },
    "papermill": {
     "duration": 0.015629,
     "end_time": "2025-12-12T13:26:13.489822",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.474193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def add_synthetic_price_features(df):\n",
    "    # 1. Recover the \"Past Returns\"\n",
    "    # forward_returns at index T represents the return for T+1.\n",
    "    # So shift(1) gives us the return realized at T (Today).\n",
    "    # We fill the first NaN with 0 to start the chain.\n",
    "    realized_returns = df['lagged_forward_returns']\n",
    "\n",
    "    # Fill NaN values in realized_returns before calculating cumulative product\n",
    "    # A common approach is to fill with 0, implying no change for missing data.\n",
    "    realized_returns_cleaned = realized_returns.fillna(0)\n",
    "\n",
    "    # 2. Build Synthetic Price Index (Start at 100)\n",
    "    # cumprod() compounds the returns to create a price curve\n",
    "    synthetic_price = 100 * (1 + realized_returns_cleaned).cumprod()\n",
    "\n",
    "    # Ensure synthetic_price is fully populated after cumprod\n",
    "    synthetic_price = synthetic_price.ffill().bfill()\n",
    "\n",
    "    # Check if there's enough data for technical indicators\n",
    "    if len(synthetic_price) < 20: # Minimum length for BBands and RSI\n",
    "        df['syn_rsi_14'] = np.nan\n",
    "        df['syn_ppo_hist'] = np.nan\n",
    "        df['syn_ppo_line'] = np.nan\n",
    "        df['syn_bb_width'] = np.nan\n",
    "        return df\n",
    "\n",
    "    # 3. Calculate RSI (Scale Invariant - Safe)\n",
    "    df['syn_rsi_14'] = ta.rsi(synthetic_price, length=14)\n",
    "\n",
    "    # 4. Calculate PPO (Percentage Price Oscillator) instead of MACD\n",
    "    # Why? Regular MACD depends on the absolute price (100 vs 4000).\n",
    "    # PPO is the percentage version of MACD, so it works perfectly\n",
    "    # on a synthetic price regardless of where it starts.\n",
    "    ppo = ta.ppo(synthetic_price)\n",
    "    df['syn_ppo_hist'] = ppo['PPOh_12_26_9'] # The Histogram\n",
    "    df['syn_ppo_line'] = ppo['PPO_12_26_9']  # The Line\n",
    "\n",
    "    # 5. (Optional) Bollinger Bands (Measure Volatility squeeze)\n",
    "    bbands = ta.bbands(synthetic_price, length=20)\n",
    "\n",
    "    # Safely access 'BBB_20_2.0'\n",
    "    if 'BBB_20_2.0' in bbands.columns:\n",
    "        df['syn_bb_width'] = bbands['BBB_20_2.0']\n",
    "    else:\n",
    "        df['syn_bb_width'] = np.nan\n",
    "        print(f\"Warning: 'BBB_20_2.0' not found in bbands output for {df.name if hasattr(df, 'name') else 'a series'}. Synthetic price length: {len(synthetic_price)}. This may be due to insufficient data or constant values.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ae6123f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:13.504111Z",
     "iopub.status.busy": "2025-12-12T13:26:13.503547Z",
     "iopub.status.idle": "2025-12-12T13:26:13.508216Z",
     "shell.execute_reply": "2025-12-12T13:26:13.507411Z"
    },
    "papermill": {
     "duration": 0.013471,
     "end_time": "2025-12-12T13:26:13.509517",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.496046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_indicator_lags(df):\n",
    "    # List of new synthetic features you just created\n",
    "    # (Adjust names if you named them differently)\n",
    "    indicators = ['syn_rsi_14', 'syn_ppo_hist', 'syn_ppo_line',  'syn_bb_width']\n",
    "\n",
    "    for col in indicators:\n",
    "        if col in df.columns:\n",
    "            # Only lag-1 is usually needed for \"Slope\" detection\n",
    "            df[f'{col}_lag_1'] = df[col].shift(1)\n",
    "\n",
    "            # Optional: lag-2 if you want to detect curvature (acceleration)\n",
    "            # df[f'{col}_lag_2'] = df[col].shift(2)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d349d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:13.523464Z",
     "iopub.status.busy": "2025-12-12T13:26:13.523029Z",
     "iopub.status.idle": "2025-12-12T13:26:13.529398Z",
     "shell.execute_reply": "2025-12-12T13:26:13.528638Z"
    },
    "papermill": {
     "duration": 0.015329,
     "end_time": "2025-12-12T13:26:13.531043",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.515714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_features(df_original, isTraining):\n",
    "    \n",
    "    df = df_original.copy()\n",
    "    \n",
    "    if isTraining:\n",
    "      df_LightGBM_target = pd.Series(create_LightGBM_target(df))\n",
    "    else:\n",
    "      df_LightGBM_target = pd.Series(create_LightGBM_target_inference(df))\n",
    "\n",
    "    if isTraining:\n",
    "      df['lagged_risk_free_rate'] = df['risk_free_rate'].shift()\n",
    "      df['lagged_forward_returns'] = df['forward_returns'].shift()\n",
    "      # The target, risk_free_rate, and forward_returns columns are raw inputs and will be dropped later\n",
    "      # We keep them for now for creating lagged features or other computations.\n",
    "    else: # Inference\n",
    "      # 'is_scored' and 'lagged_market_forward_excess_returns' are specific to test data, not features\n",
    "      df.drop(columns=['is_scored', 'lagged_market_forward_excess_returns'], inplace=True, errors='ignore')\n",
    "\n",
    "    print(f\"Shape before adding new features: {df.shape}\")\n",
    "    df_lags = add_return_target_lags(df, df_LightGBM_target)\n",
    "    df_synt_lags = add_synthetic_price_features(df_lags).pipe(add_indicator_lags)\n",
    "\n",
    "    # Define all columns that should NOT be part of the final feature set for the model\n",
    "    columns_to_drop_from_X = [\n",
    "        'date_id',\n",
    "        'target',                 # Original target (from train) or test's 'target' (which is lagged_forward_returns)\n",
    "        'risk_free_rate',         # Raw value, its lagged version is kept\n",
    "        'forward_returns',        # Raw value, its lagged version is kept\n",
    "        # 'is_scored' and 'lagged_market_forward_excess_returns' are dropped earlier for inference path\n",
    "        # or don't exist in training path, handled by errors='ignore'\n",
    "    ]\n",
    "\n",
    "    # Drop these non-feature columns consistently for both training and inference\n",
    "    df_final_features = df_synt_lags.drop(columns=columns_to_drop_from_X, errors='ignore')\n",
    "\n",
    "    print(f\"Shape after feature generation and dropping non-features: {df_final_features.shape}\")\n",
    "    return df_final_features, df_LightGBM_target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae5fb5e",
   "metadata": {
    "papermill": {
     "duration": 0.005936,
     "end_time": "2025-12-12T13:26:13.543317",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.537381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a706e5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:13.558357Z",
     "iopub.status.busy": "2025-12-12T13:26:13.557695Z",
     "iopub.status.idle": "2025-12-12T13:26:18.292305Z",
     "shell.execute_reply": "2025-12-12T13:26:18.291211Z"
    },
    "papermill": {
     "duration": 4.743355,
     "end_time": "2025-12-12T13:26:18.294111",
     "exception": false,
     "start_time": "2025-12-12T13:26:13.550756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "# ---------------------------------------------------------------------------------\n",
    "# 2. The Training Loop\n",
    "# ---------------------------------------------------------------------------------\n",
    "\n",
    "def train_lightgbm_policy(X, y, feature_names, num_boost_round, best_params, weight_min):\n",
    "    \"\"\"\n",
    "    X: Input Features (LSTM Hidden States + Lags + Macro)\n",
    "    y: The Oracle Target (0 to 2)\n",
    "    df_context: DataFrame containing raw returns for the metric calculation\n",
    "    \"\"\"\n",
    "\n",
    "    models = []\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # B. WEIGHTING: Prioritize Recent Data\n",
    "    # -------------------------------------------------------\n",
    "    # Create a linear decay weight.\n",
    "    # Recent data (end of train) gets weight 1.0, oldest gets 0.5\n",
    "    w_train = np.linspace(weight_min, 1.0, len(X))\n",
    "\n",
    "    # C. Create Datasets (Pass weights here!)\n",
    "    dtrain = lgb.Dataset(X, label=y,\n",
    "                          feature_name=feature_names, weight=w_train)\n",
    "\n",
    "    # E. Train\n",
    "\n",
    "    model = lgb.train(\n",
    "        best_params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "    )\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d3f4e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:18.308371Z",
     "iopub.status.busy": "2025-12-12T13:26:18.307813Z",
     "iopub.status.idle": "2025-12-12T13:26:18.393386Z",
     "shell.execute_reply": "2025-12-12T13:26:18.392595Z"
    },
    "papermill": {
     "duration": 0.09447,
     "end_time": "2025-12-12T13:26:18.394806",
     "exception": false,
     "start_time": "2025-12-12T13:26:18.300336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before adding new features: (9048, 100)\n",
      "Shape after feature generation and dropping non-features: (9048, 112)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9047, 112)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9047,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_features_train, df_LightGBM_target = generate_features(df_train.copy(), isTraining=True)\n",
    "X_final = df_features_train.iloc[:-1]\n",
    "y_final = df_LightGBM_target.iloc[:-1]\n",
    "display(X_final.shape)\n",
    "display(y_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a25fb",
   "metadata": {
    "papermill": {
     "duration": 0.006367,
     "end_time": "2025-12-12T13:26:18.407608",
     "exception": false,
     "start_time": "2025-12-12T13:26:18.401241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Best params weighted - rolling windows\n",
    "\n",
    "{'num_leaves': 137,\n",
    " 'max_depth': 8,\n",
    " 'min_data_in_leaf': 70,\n",
    " 'learning_rate': 0.0322378071317859,\n",
    " 'lambda_l1': 0.005456545606883056,\n",
    " 'lambda_l2': 0.05908594087517651,\n",
    " 'feature_fraction': 0.8393936179595116,\n",
    " 'bagging_fraction': 0.9491692279948203,\n",
    " 'bagging_freq': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6e9e3f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:18.422096Z",
     "iopub.status.busy": "2025-12-12T13:26:18.421785Z",
     "iopub.status.idle": "2025-12-12T13:26:18.426885Z",
     "shell.execute_reply": "2025-12-12T13:26:18.425995Z"
    },
    "papermill": {
     "duration": 0.013914,
     "end_time": "2025-12-12T13:26:18.428257",
     "exception": false,
     "start_time": "2025-12-12T13:26:18.414343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#best_params_weighted=study.best_params\n",
    "best_params_weighted = {\n",
    " 'num_leaves': 137,\n",
    " 'max_depth': 8,\n",
    " 'min_data_in_leaf': 70,\n",
    " 'learning_rate': 0.0322378071317859,\n",
    " 'lambda_l1': 0.005456545606883056,\n",
    " 'lambda_l2': 0.05908594087517651,\n",
    " 'feature_fraction': 0.8393936179595116,\n",
    " 'bagging_fraction': 0.9491692279948203,\n",
    " 'bagging_freq': 4,\n",
    " 'objective': 'multiclass',\n",
    " 'metric': 'multi_logloss',\n",
    " 'num_class': 3,\n",
    " 'verbosity': -1,\n",
    " 'boosting_type': 'gbdt',\n",
    " 'n_jobs': -1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e1282a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:18.443087Z",
     "iopub.status.busy": "2025-12-12T13:26:18.442800Z",
     "iopub.status.idle": "2025-12-12T13:26:22.647660Z",
     "shell.execute_reply": "2025-12-12T13:26:22.646920Z"
    },
    "papermill": {
     "duration": 4.215763,
     "end_time": "2025-12-12T13:26:22.650446",
     "exception": false,
     "start_time": "2025-12-12T13:26:18.434683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_LightGBM_weighted = train_lightgbm_policy(X_final, y_final,\n",
    "                                                 X_final.columns.tolist(),\n",
    "                                                 num_boost_round = 90, best_params=best_params_weighted,weight_min=0.5 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5eeec",
   "metadata": {
    "papermill": {
     "duration": 0.006067,
     "end_time": "2025-12-12T13:26:22.663717",
     "exception": false,
     "start_time": "2025-12-12T13:26:22.657650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Best params unweighted, expanding windows , 3 folds ####\n",
    "\n",
    "\n",
    "best_params_unweighted_expanding = {'num_leaves': 149,\n",
    "                                    'max_depth': 7,\n",
    "                                    'min_data_in_leaf': 54,\n",
    "                                    'learning_rate': 0.0345,\n",
    "                                    'lambda_l1': 0.8426,\n",
    "                                    'lambda_l2': 0.0611,\n",
    "                                    'feature_fraction': 0.9498,\n",
    "                                    'bagging_fraction': 0.8619,\n",
    "                                    'bagging_freq': 6}\n",
    "best_params_unweighted_expanding['objective'] = 'multiclass',\n",
    "best_params_unweighted_expanding['metric'] = 'multi_logloss',\n",
    "best_params_unweighted_expanding['num_class']= 3,\n",
    "best_params_unweighted_expanding['verbosity'] = -1\n",
    "best_params_unweighted_expanding['boosting_type'] = 'gbdt'\n",
    "best_params_unweighted_expanding['n_jobs'] = -1\n",
    "\n",
    "\n",
    "--- Training Fold 1 ---\n",
    "Training until validation scores don't improve for 100 rounds\n",
    "[50]\tvalid_0's multi_logloss: 1.02854\tvalid_0's comp_score: 2.52809\n",
    "[100]\tvalid_0's multi_logloss: 1.02798\tvalid_0's comp_score: 2.5133\n",
    "[150]\tvalid_0's multi_logloss: 1.03308\tvalid_0's comp_score: 2.51957\n",
    "Early stopping, best iteration is:\n",
    "[71]\tvalid_0's multi_logloss: 1.02161\tvalid_0's comp_score: 2.53852\n",
    "Evaluated only: multi_logloss\n",
    "--- Training Fold 2 ---\n",
    "Training until validation scores don't improve for 100 rounds\n",
    "[50]\tvalid_0's multi_logloss: 1.05794\tvalid_0's comp_score: 0.215383\n",
    "[100]\tvalid_0's multi_logloss: 1.05924\tvalid_0's comp_score: 0.165959\n",
    "Early stopping, best iteration is:\n",
    "[36]\tvalid_0's multi_logloss: 1.0539\tvalid_0's comp_score: 0.246042\n",
    "Evaluated only: multi_logloss\n",
    "--- Training Fold 3 ---\n",
    "Training until validation scores don't improve for 100 rounds\n",
    "[50]\tvalid_0's multi_logloss: 0.99313\tvalid_0's comp_score: 1.30788\n",
    "[100]\tvalid_0's multi_logloss: 0.987647\tvalid_0's comp_score: 1.29678\n",
    "[150]\tvalid_0's multi_logloss: 0.979411\tvalid_0's comp_score: 1.36566\n",
    "[200]\tvalid_0's multi_logloss: 0.985436\tvalid_0's comp_score: 1.34281\n",
    "Early stopping, best iteration is:\n",
    "[122]\tvalid_0's multi_logloss: 0.978066\tvalid_0's comp_score: 1.35932\n",
    "Evaluated only: multi_logloss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f44b3dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:22.677344Z",
     "iopub.status.busy": "2025-12-12T13:26:22.677072Z",
     "iopub.status.idle": "2025-12-12T13:26:22.682751Z",
     "shell.execute_reply": "2025-12-12T13:26:22.681677Z"
    },
    "papermill": {
     "duration": 0.014428,
     "end_time": "2025-12-12T13:26:22.684298",
     "exception": false,
     "start_time": "2025-12-12T13:26:22.669870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params_unweighted_expanding = {'num_leaves': 149,\n",
    "                                    'max_depth': 7,\n",
    "                                    'min_data_in_leaf': 54,\n",
    "                                    'learning_rate': 0.0345,\n",
    "                                    'lambda_l1': 0.8426,\n",
    "                                    'lambda_l2': 0.0611,\n",
    "                                    'feature_fraction': 0.9498,\n",
    "                                    'bagging_fraction': 0.8619,\n",
    "                                    'bagging_freq': 6}\n",
    "best_params_unweighted_expanding['objective'] = 'multiclass',\n",
    "best_params_unweighted_expanding['metric'] = 'multi_logloss',\n",
    "best_params_unweighted_expanding['num_class']= 3,\n",
    "best_params_unweighted_expanding['verbosity'] = -1\n",
    "best_params_unweighted_expanding['boosting_type'] = 'gbdt'\n",
    "best_params_unweighted_expanding['n_jobs'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d02a221b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:22.698666Z",
     "iopub.status.busy": "2025-12-12T13:26:22.698376Z",
     "iopub.status.idle": "2025-12-12T13:26:24.651107Z",
     "shell.execute_reply": "2025-12-12T13:26:24.650380Z"
    },
    "papermill": {
     "duration": 1.962488,
     "end_time": "2025-12-12T13:26:24.653180",
     "exception": false,
     "start_time": "2025-12-12T13:26:22.690692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_LightGBM_unweighted_expanding  = train_lightgbm_policy(X_final, y_final,\n",
    "                                                 X_final.columns.tolist(),\n",
    "                                                 num_boost_round = 40, best_params=best_params_unweighted_expanding,weight_min=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198edc3",
   "metadata": {
    "papermill": {
     "duration": 0.006193,
     "end_time": "2025-12-12T13:26:24.667321",
     "exception": false,
     "start_time": "2025-12-12T13:26:24.661128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ce7fe2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:24.681268Z",
     "iopub.status.busy": "2025-12-12T13:26:24.681000Z",
     "iopub.status.idle": "2025-12-12T13:26:24.691656Z",
     "shell.execute_reply": "2025-12-12T13:26:24.690676Z"
    },
    "papermill": {
     "duration": 0.019409,
     "end_time": "2025-12-12T13:26:24.693204",
     "exception": false,
     "start_time": "2025-12-12T13:26:24.673795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_history_df = df_train.copy()\n",
    "initial_history_df['lagged_risk_free_rate'] = initial_history_df['risk_free_rate'].shift()\n",
    "initial_history_df['lagged_forward_returns'] = initial_history_df['forward_returns'].shift()\n",
    "initial_history_df.drop(columns=['target', 'risk_free_rate', 'forward_returns'], inplace=True)\n",
    "initial_history_df=initial_history_df.tail(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c243430b",
   "metadata": {
    "papermill": {
     "duration": 0.006116,
     "end_time": "2025-12-12T13:26:24.705819",
     "exception": false,
     "start_time": "2025-12-12T13:26:24.699703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9546989b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:24.719939Z",
     "iopub.status.busy": "2025-12-12T13:26:24.719610Z",
     "iopub.status.idle": "2025-12-12T13:26:24.726895Z",
     "shell.execute_reply": "2025-12-12T13:26:24.726095Z"
    },
    "papermill": {
     "duration": 0.016311,
     "end_time": "2025-12-12T13:26:24.728340",
     "exception": false,
     "start_time": "2025-12-12T13:26:24.712029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(test: pl.DataFrame) -> float:\n",
    "    # 1. Feature Engineering\n",
    "    # Ensure this function generates the exact same columns as your training data!\n",
    "    # (Drop the rename if it's not strictly needed for your create_example_dataset logic)\n",
    "    # test = test.rename({'lagged_forward_returns':'target'})\n",
    "\n",
    "    global initial_history_df\n",
    "    df_test= test.to_pandas()\n",
    "    # Corrected drop operation:\n",
    "    #df_test = df_test.drop(columns=['lagged_market_forward_excess_returns'], errors='ignore')\n",
    "    \n",
    "    history_slice=initial_history_df[initial_history_df['date_id']<df_test['date_id'].iloc[0]]\n",
    "\n",
    "    df_history_all=pd.concat([history_slice, df_test], axis=0, ignore_index=True)[-100:]\n",
    "    X_test, _ = generate_features(df_history_all, isTraining=False) # Get only the features, ignore the target\n",
    "    X_test=X_test.iloc[-1:]\n",
    "\n",
    "    # 2. Get Probabilities\n",
    "    # LightGBM .predict() returns shape (n_samples, 3)\n",
    "    # We take [0] because we are predicting 1 row at a time in inference\n",
    "    probs_weighted = models_LightGBM_weighted[0].predict(X_test)\n",
    "    probs_unweighted_exp = models_LightGBM_unweighted_expanding[0].predict(X_test)\n",
    "    probs_mean= (probs_weighted + probs_unweighted_exp) / 2\n",
    "\n",
    "    # --- DEBUGGING BLOCK ---\n",
    "    print(\"\\n--- DEBUGGING STEP ---\")\n",
    "    print(f\"Raw Input Timestamp: {df_test.index[0] if not df_test.index.empty else 'No Index'}\")\n",
    "    print(f\"Features (First 3 cols): {X_test.iloc[0, :3].values}\")\n",
    "    print(\"Features shape \",X_test.shape)\n",
    "    print(f\"Model Output Probs: {probs_mean}\")\n",
    "\n",
    "    # Flatten probs_mean from (1, 3) to (3,) for a single prediction\n",
    "    probs_mean = probs_mean[0]\n",
    "\n",
    "    # probs is something like [0.10, 0.60, 0.30]\n",
    "    # 3. Calculate Weighted Position\n",
    "    # P(Hold)*1.0 + P(Buy)*2.0\n",
    "    # (P(Sell) is multiplied by 0, so we ignore it)\n",
    "    position_ensemble = (probs_mean[1] * 1.0) + (probs_mean[2] * 2.0)\n",
    "\n",
    "    # 4. Clip for Safety (Strictly between 0 and 2)\n",
    "    final_position = np.clip(position_ensemble, 0.0, 2.0)\n",
    "\n",
    "    if len(initial_history_df) > 500:\n",
    "        initial_history_df = initial_history_df.iloc[-500:]\n",
    "        \n",
    "    initial_history_df = pd.concat([initial_history_df, df_test], axis=0, ignore_index=True)\n",
    "\n",
    "    return float(final_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c206f993",
   "metadata": {
    "papermill": {
     "duration": 0.006066,
     "end_time": "2025-12-12T13:26:24.740839",
     "exception": false,
     "start_time": "2025-12-12T13:26:24.734773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Launch Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eb14154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T13:26:24.754550Z",
     "iopub.status.busy": "2025-12-12T13:26:24.754278Z",
     "iopub.status.idle": "2025-12-12T13:26:25.275724Z",
     "shell.execute_reply": "2025-12-12T13:26:25.274098Z"
    },
    "papermill": {
     "duration": 0.53043,
     "end_time": "2025-12-12T13:26:25.277450",
     "exception": false,
     "start_time": "2025-12-12T13:26:24.747020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Preparing clean test data for local simulation...\n",
      "✅ Clean data saved. Starting Local Gateway...\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n",
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 0.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.24324007 0.43909402 0.31766591]]\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n",
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 0.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.24648848 0.40601516 0.34749636]]\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n",
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 0.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.23819889 0.29382132 0.4679798 ]]\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 0.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.25452611 0.34625808 0.39921581]]\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n",
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 0.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.19550976 0.47892211 0.32556813]]\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n",
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 0.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.2036083  0.44712138 0.34927032]]\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n",
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 0.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.22621218 0.42253951 0.35124831]]\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n",
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 1.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.26481678 0.32238262 0.4128006 ]]\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n",
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 0.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.23805479 0.35130881 0.4106364 ]]\n",
      "Shape before adding new features: (100, 97)\n",
      "Shape after feature generation and dropping non-features: (100, 112)\n",
      "\n",
      "--- DEBUGGING STEP ---\n",
      "Raw Input Timestamp: 0\n",
      "Features (First 3 cols): <FloatingArray>\n",
      "[0.0, 0.0, 0.0]\n",
      "Length: 3, dtype: Float64\n",
      "Features shape  (1, 112)\n",
      "Model Output Probs: [[0.15792887 0.60022595 0.24184518]]\n",
      "✅ Success! submission.parquet generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the Server\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "# 2. The Logic Switch\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # ==========================================\n",
    "    # SCENARIO A: REAL SUBMISSION\n",
    "    # ==========================================\n",
    "    # Runs on the official hidden test set (which is already clean).\n",
    "    print(\"🚀 Starting Official Submission Server...\")\n",
    "    inference_server.serve()\n",
    "    \n",
    "else:\n",
    "    # ==========================================\n",
    "    # SCENARIO B: SAVE & RUN ALL (The Fix)\n",
    "    # ==========================================\n",
    "    # We create a temporary \"clean\" folder to trick the Gateway into running\n",
    "    # successfully so it generates the required 'submission.parquet' file.\n",
    "    \n",
    "    print(\"🛠️ Preparing clean test data for local simulation...\")\n",
    "    \n",
    "    # A. Define paths\n",
    "    local_data_path = '/kaggle/input/hull-tactical-market-prediction/'\n",
    "    temp_dir = 'temp_data'\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "    \n",
    "    # B. Load the buggy test.csv\n",
    "    # The error happens because 'is_scored' is Text instead of Number\n",
    "    df_temp = pd.read_csv(os.path.join(local_data_path, 'test.csv'))\n",
    "    \n",
    "    # C. Fix the column (Force it to Integer)\n",
    "    # We coerce errors to NaN, fill NaNs with 0, and cast to int\n",
    "    if 'is_scored' in df_temp.columns:\n",
    "        df_temp['is_scored'] = pd.to_numeric(df_temp['is_scored'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # D. Save the Clean Version to the temp folder\n",
    "    df_temp.to_csv(os.path.join(temp_dir, 'test.csv'), index=False)\n",
    "    \n",
    "    # E. Copy the other necessary file (targets.csv) if it exists, or ignore\n",
    "    # The gateway usually only strictly needs test.csv to start the loop\n",
    "    \n",
    "    print(\"✅ Clean data saved. Starting Local Gateway...\")\n",
    "    \n",
    "    # F. Run Gateway pointing to the CLEAN folder\n",
    "    # This generates 'submission.parquet' without crashing!\n",
    "    try:\n",
    "        inference_server.run_local_gateway((temp_dir,))\n",
    "        print(\"✅ Success! submission.parquet generated.\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Gateway Warning: {e}\")\n",
    "        # Even if it warns, check if submission.parquet exists\n",
    "        if os.path.exists('submission.parquet'):\n",
    "            print(\"   (File exists, so we are good to go!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6aa9ce",
   "metadata": {
    "papermill": {
     "duration": 0.007639,
     "end_time": "2025-12-12T13:26:25.292327",
     "exception": false,
     "start_time": "2025-12-12T13:26:25.284688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14861981,
     "isSourceIdPinned": false,
     "sourceId": 111543,
     "sourceType": "competition"
    },
    {
     "datasetId": 9001250,
     "sourceId": 14127338,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.052221,
   "end_time": "2025-12-12T13:26:26.220137",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T13:25:56.167916",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
